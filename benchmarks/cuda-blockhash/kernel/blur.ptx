//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-31442593
// Cuda compilation tools, release 11.7, V11.7.99
// Based on NVVM 7.0.1
//

.version 7.7
.target sm_52
.address_size 64

	// .globl	blur_and_sub

.visible .entry blur_and_sub(
	.param .u64 blur_and_sub_param_0,
	.param .u64 blur_and_sub_param_1,
	.param .u64 blur_and_sub_param_2,
	.param .u64 blur_and_sub_param_3,
	.param .u32 blur_and_sub_param_4,
	.param .u32 blur_and_sub_param_5,
	.param .u64 blur_and_sub_param_6,
	.param .u64 blur_and_sub_param_7,
	.param .u32 blur_and_sub_param_8,
	.param .u32 blur_and_sub_param_9
)
{
	.reg .pred 	%p<14>;
	.reg .b16 	%rs<18>;
	.reg .f32 	%f<67>;
	.reg .b32 	%r<120>;
	.reg .b64 	%rd<70>;


	ld.param.u64 	%rd6, [blur_and_sub_param_0];
	ld.param.u64 	%rd7, [blur_and_sub_param_2];
	ld.param.u64 	%rd8, [blur_and_sub_param_3];
	ld.param.u32 	%r41, [blur_and_sub_param_4];
	ld.param.u32 	%r42, [blur_and_sub_param_5];
	ld.param.u64 	%rd9, [blur_and_sub_param_6];
	ld.param.u64 	%rd10, [blur_and_sub_param_7];
	ld.param.u32 	%r43, [blur_and_sub_param_8];
	ld.param.u32 	%r44, [blur_and_sub_param_9];
	cvta.to.global.u64 	%rd11, %rd8;
	cvta.to.global.u64 	%rd1, %rd10;
	cvta.to.global.u64 	%rd2, %rd6;
	cvta.to.global.u64 	%rd3, %rd9;
	mov.u32 	%r1, %tid.x;
	setp.lt.u32 	%p1, %r1, %r42;
	mov.u32 	%r2, %tid.y;
	setp.lt.u32 	%p2, %r2, %r41;
	and.pred  	%p3, %p2, %p1;
	mad.lo.s32 	%r45, %r1, %r41, %r2;
	cvt.u64.u32 	%rd12, %r45;
	cvta.to.global.u64 	%rd13, %rd7;
	add.s64 	%rd4, %rd13, %rd12;
	add.s64 	%rd5, %rd11, %rd12;
	@%p3 bra 	$L__BB0_1;
	bra.uni 	$L__BB0_18;

$L__BB0_1:
	shr.u32 	%r3, %r43, 1;
	neg.s32 	%r114, %r3;
	setp.lt.s32 	%p4, %r3, %r114;
	mov.f32 	%f65, 0f00000000;
	mov.f32 	%f60, %f65;
	@%p4 bra 	$L__BB0_9;

	add.s32 	%r5, %r42, -1;
	and.b32  	%r6, %r43, -2;
	or.b32  	%r46, %r6, 1;
	mov.u32 	%r47, 1;
	and.b32  	%r7, %r46, 3;
	mov.u32 	%r48, 3;
	sub.s32 	%r49, %r2, %r3;
	add.s32 	%r8, %r41, -1;
	min.u32 	%r9, %r8, %r49;
	sub.s32 	%r10, %r47, %r3;
	add.s32 	%r50, %r10, %r2;
	min.u32 	%r11, %r8, %r50;
	add.s32 	%r51, %r50, 1;
	min.u32 	%r12, %r8, %r51;
	sub.s32 	%r13, %r48, %r3;
	setp.eq.s32 	%p5, %r7, 1;
	setp.lt.u32 	%p6, %r6, 3;

$L__BB0_3:
	add.s32 	%r52, %r114, %r1;
	min.u32 	%r53, %r5, %r52;
	add.s32 	%r54, %r114, %r3;
	mul.lo.s32 	%r15, %r54, %r43;
	mul.lo.s32 	%r16, %r53, %r41;
	mul.wide.u32 	%rd14, %r15, 4;
	add.s64 	%rd15, %rd3, %rd14;
	add.s32 	%r55, %r9, %r16;
	cvt.u64.u32 	%rd16, %r55;
	add.s64 	%rd17, %rd2, %rd16;
	ld.global.u8 	%rs1, [%rd17];
	cvt.rn.f32.u16 	%f19, %rs1;
	ld.global.f32 	%f20, [%rd15];
	fma.rn.f32 	%f60, %f20, %f19, %f60;
	mov.u32 	%r116, %r10;
	@%p5 bra 	$L__BB0_5;

	add.s32 	%r56, %r15, 1;
	mul.wide.u32 	%rd18, %r56, 4;
	add.s64 	%rd19, %rd3, %rd18;
	add.s32 	%r57, %r11, %r16;
	cvt.u64.u32 	%rd20, %r57;
	add.s64 	%rd21, %rd2, %rd20;
	ld.global.u8 	%rs2, [%rd21];
	cvt.rn.f32.u16 	%f21, %rs2;
	ld.global.f32 	%f22, [%rd19];
	fma.rn.f32 	%f23, %f22, %f21, %f60;
	add.s32 	%r58, %r15, 2;
	mul.wide.u32 	%rd22, %r58, 4;
	add.s64 	%rd23, %rd3, %rd22;
	add.s32 	%r59, %r12, %r16;
	cvt.u64.u32 	%rd24, %r59;
	add.s64 	%rd25, %rd2, %rd24;
	ld.global.u8 	%rs3, [%rd25];
	cvt.rn.f32.u16 	%f24, %rs3;
	ld.global.f32 	%f25, [%rd23];
	fma.rn.f32 	%f60, %f25, %f24, %f23;
	mov.u32 	%r116, %r13;

$L__BB0_5:
	@%p6 bra 	$L__BB0_8;

	add.s32 	%r18, %r15, %r3;

$L__BB0_7:
	add.s32 	%r60, %r116, %r2;
	min.u32 	%r61, %r8, %r60;
	add.s32 	%r62, %r18, %r116;
	mul.wide.u32 	%rd26, %r62, 4;
	add.s64 	%rd27, %rd3, %rd26;
	add.s32 	%r63, %r61, %r16;
	cvt.u64.u32 	%rd28, %r63;
	add.s64 	%rd29, %rd2, %rd28;
	ld.global.u8 	%rs4, [%rd29];
	cvt.rn.f32.u16 	%f26, %rs4;
	ld.global.f32 	%f27, [%rd27];
	fma.rn.f32 	%f28, %f27, %f26, %f60;
	add.s32 	%r64, %r116, 1;
	add.s32 	%r65, %r64, %r2;
	min.u32 	%r66, %r8, %r65;
	add.s32 	%r67, %r18, %r64;
	mul.wide.u32 	%rd30, %r67, 4;
	add.s64 	%rd31, %rd3, %rd30;
	add.s32 	%r68, %r66, %r16;
	cvt.u64.u32 	%rd32, %r68;
	add.s64 	%rd33, %rd2, %rd32;
	ld.global.u8 	%rs5, [%rd33];
	cvt.rn.f32.u16 	%f29, %rs5;
	ld.global.f32 	%f30, [%rd31];
	fma.rn.f32 	%f31, %f30, %f29, %f28;
	add.s32 	%r69, %r116, 2;
	add.s32 	%r70, %r69, %r2;
	min.u32 	%r71, %r8, %r70;
	add.s32 	%r72, %r18, %r69;
	mul.wide.u32 	%rd34, %r72, 4;
	add.s64 	%rd35, %rd3, %rd34;
	add.s32 	%r73, %r71, %r16;
	cvt.u64.u32 	%rd36, %r73;
	add.s64 	%rd37, %rd2, %rd36;
	ld.global.u8 	%rs6, [%rd37];
	cvt.rn.f32.u16 	%f32, %rs6;
	ld.global.f32 	%f33, [%rd35];
	fma.rn.f32 	%f34, %f33, %f32, %f31;
	add.s32 	%r74, %r116, 3;
	add.s32 	%r75, %r74, %r2;
	min.u32 	%r76, %r8, %r75;
	add.s32 	%r77, %r18, %r74;
	mul.wide.u32 	%rd38, %r77, 4;
	add.s64 	%rd39, %rd3, %rd38;
	add.s32 	%r78, %r76, %r16;
	cvt.u64.u32 	%rd40, %r78;
	add.s64 	%rd41, %rd2, %rd40;
	ld.global.u8 	%rs7, [%rd41];
	cvt.rn.f32.u16 	%f35, %rs7;
	ld.global.f32 	%f36, [%rd39];
	fma.rn.f32 	%f60, %f36, %f35, %f34;
	add.s32 	%r116, %r116, 4;
	setp.lt.s32 	%p7, %r74, %r3;
	@%p7 bra 	$L__BB0_7;

$L__BB0_8:
	add.s32 	%r21, %r114, 1;
	setp.lt.s32 	%p8, %r114, %r3;
	mov.u32 	%r114, %r21;
	@%p8 bra 	$L__BB0_3;

$L__BB0_9:
	cvt.rzi.u32.f32 	%r79, %f60;
	st.global.u8 	[%rd4], %r79;
	shr.u32 	%r22, %r44, 1;
	neg.s32 	%r117, %r22;
	setp.lt.s32 	%p9, %r22, %r117;
	@%p9 bra 	$L__BB0_17;

	add.s32 	%r24, %r42, -1;
	and.b32  	%r25, %r44, -2;
	or.b32  	%r80, %r25, 1;
	mov.u32 	%r81, 1;
	and.b32  	%r26, %r80, 3;
	mov.u32 	%r82, 3;
	sub.s32 	%r83, %r2, %r22;
	add.s32 	%r27, %r41, -1;
	min.u32 	%r28, %r27, %r83;
	sub.s32 	%r29, %r81, %r22;
	add.s32 	%r84, %r29, %r2;
	min.u32 	%r30, %r27, %r84;
	add.s32 	%r85, %r84, 1;
	min.u32 	%r31, %r27, %r85;
	sub.s32 	%r32, %r82, %r22;
	setp.eq.s32 	%p10, %r26, 1;
	setp.lt.u32 	%p11, %r25, 3;

$L__BB0_11:
	add.s32 	%r86, %r117, %r1;
	min.u32 	%r87, %r24, %r86;
	add.s32 	%r88, %r117, %r22;
	mul.lo.s32 	%r34, %r88, %r44;
	mul.lo.s32 	%r35, %r87, %r41;
	mul.wide.u32 	%rd42, %r34, 4;
	add.s64 	%rd43, %rd1, %rd42;
	add.s32 	%r89, %r28, %r35;
	cvt.u64.u32 	%rd44, %r89;
	add.s64 	%rd45, %rd2, %rd44;
	ld.global.u8 	%rs8, [%rd45];
	cvt.rn.f32.u16 	%f39, %rs8;
	ld.global.f32 	%f40, [%rd43];
	fma.rn.f32 	%f65, %f40, %f39, %f65;
	mov.u32 	%r119, %r29;
	@%p10 bra 	$L__BB0_13;

	add.s32 	%r90, %r34, 1;
	mul.wide.u32 	%rd46, %r90, 4;
	add.s64 	%rd47, %rd1, %rd46;
	add.s32 	%r91, %r30, %r35;
	cvt.u64.u32 	%rd48, %r91;
	add.s64 	%rd49, %rd2, %rd48;
	ld.global.u8 	%rs9, [%rd49];
	cvt.rn.f32.u16 	%f41, %rs9;
	ld.global.f32 	%f42, [%rd47];
	fma.rn.f32 	%f43, %f42, %f41, %f65;
	add.s32 	%r92, %r34, 2;
	mul.wide.u32 	%rd50, %r92, 4;
	add.s64 	%rd51, %rd1, %rd50;
	add.s32 	%r93, %r31, %r35;
	cvt.u64.u32 	%rd52, %r93;
	add.s64 	%rd53, %rd2, %rd52;
	ld.global.u8 	%rs10, [%rd53];
	cvt.rn.f32.u16 	%f44, %rs10;
	ld.global.f32 	%f45, [%rd51];
	fma.rn.f32 	%f65, %f45, %f44, %f43;
	mov.u32 	%r119, %r32;

$L__BB0_13:
	@%p11 bra 	$L__BB0_16;

	add.s32 	%r37, %r34, %r22;

$L__BB0_15:
	add.s32 	%r94, %r119, %r2;
	min.u32 	%r95, %r27, %r94;
	add.s32 	%r96, %r37, %r119;
	mul.wide.u32 	%rd54, %r96, 4;
	add.s64 	%rd55, %rd1, %rd54;
	add.s32 	%r97, %r95, %r35;
	cvt.u64.u32 	%rd56, %r97;
	add.s64 	%rd57, %rd2, %rd56;
	ld.global.u8 	%rs11, [%rd57];
	cvt.rn.f32.u16 	%f46, %rs11;
	ld.global.f32 	%f47, [%rd55];
	fma.rn.f32 	%f48, %f47, %f46, %f65;
	add.s32 	%r98, %r119, 1;
	add.s32 	%r99, %r98, %r2;
	min.u32 	%r100, %r27, %r99;
	add.s32 	%r101, %r37, %r98;
	mul.wide.u32 	%rd58, %r101, 4;
	add.s64 	%rd59, %rd1, %rd58;
	add.s32 	%r102, %r100, %r35;
	cvt.u64.u32 	%rd60, %r102;
	add.s64 	%rd61, %rd2, %rd60;
	ld.global.u8 	%rs12, [%rd61];
	cvt.rn.f32.u16 	%f49, %rs12;
	ld.global.f32 	%f50, [%rd59];
	fma.rn.f32 	%f51, %f50, %f49, %f48;
	add.s32 	%r103, %r119, 2;
	add.s32 	%r104, %r103, %r2;
	min.u32 	%r105, %r27, %r104;
	add.s32 	%r106, %r37, %r103;
	mul.wide.u32 	%rd62, %r106, 4;
	add.s64 	%rd63, %rd1, %rd62;
	add.s32 	%r107, %r105, %r35;
	cvt.u64.u32 	%rd64, %r107;
	add.s64 	%rd65, %rd2, %rd64;
	ld.global.u8 	%rs13, [%rd65];
	cvt.rn.f32.u16 	%f52, %rs13;
	ld.global.f32 	%f53, [%rd63];
	fma.rn.f32 	%f54, %f53, %f52, %f51;
	add.s32 	%r108, %r119, 3;
	add.s32 	%r109, %r108, %r2;
	min.u32 	%r110, %r27, %r109;
	add.s32 	%r111, %r37, %r108;
	mul.wide.u32 	%rd66, %r111, 4;
	add.s64 	%rd67, %rd1, %rd66;
	add.s32 	%r112, %r110, %r35;
	cvt.u64.u32 	%rd68, %r112;
	add.s64 	%rd69, %rd2, %rd68;
	ld.global.u8 	%rs14, [%rd69];
	cvt.rn.f32.u16 	%f55, %rs14;
	ld.global.f32 	%f56, [%rd67];
	fma.rn.f32 	%f65, %f56, %f55, %f54;
	add.s32 	%r119, %r119, 4;
	setp.lt.s32 	%p12, %r108, %r22;
	@%p12 bra 	$L__BB0_15;

$L__BB0_16:
	add.s32 	%r40, %r117, 1;
	setp.lt.s32 	%p13, %r117, %r22;
	mov.u32 	%r117, %r40;
	@%p13 bra 	$L__BB0_11;

$L__BB0_17:
	cvt.rzi.u32.f32 	%r113, %f65;
	st.global.u8 	[%rd5], %r113;

$L__BB0_18:
	ld.global.u8 	%rs15, [%rd5];
	ld.global.u8 	%rs16, [%rd4];
	sub.s16 	%rs17, %rs16, %rs15;
	st.global.u8 	[%rd4], %rs17;
	ret;

}

